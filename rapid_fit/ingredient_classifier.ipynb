{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ingredient Line Classifier\n",
        "\n",
        "This notebook builds a classifier to tag ingredient lines into 4 categories:\n",
        "- `ingredient_only` — e.g., \"Tomato\"\n",
        "- `ingredient_with_qty` — e.g., \"Milk 200 ml\"\n",
        "- `instruction_like` — e.g., \"Chop the onions\"\n",
        "- `non_food` — e.g., \"Plastic wrap\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (12, 2)\n",
            "\n",
            "Training data:\n",
            "                     text                label\n",
            "0                  Tomato      ingredient_only\n",
            "1                   Onion      ingredient_only\n",
            "2             Butter 50 g  ingredient_with_qty\n",
            "3             Milk 200 ml  ingredient_with_qty\n",
            "4         Chop the onions     instruction_like\n",
            "5   Simmer for 10 minutes     instruction_like\n",
            "6            Plastic wrap             non_food\n",
            "7            Baking paper             non_food\n",
            "8                  Eggs 2  ingredient_with_qty\n",
            "9               Olive oil      ingredient_only\n",
            "10        Slice the bread     instruction_like\n",
            "11            Paper towel             non_food\n",
            "\n",
            "Test data shape: (8, 2)\n",
            "\n",
            "Test data:\n",
            "                 text  label\n",
            "0              Garlic    NaN\n",
            "1          Sugar 20 g    NaN\n",
            "2       Warm in a pan    NaN\n",
            "3       Aluminum foil    NaN\n",
            "4          Rice 150 g    NaN\n",
            "5               Cumin    NaN\n",
            "6  Stir for 2 minutes    NaN\n",
            "7                Salt    NaN\n"
          ]
        }
      ],
      "source": [
        "# Load training data\n",
        "train_df = pd.read_csv('data/train.csv')\n",
        "test_df = pd.read_csv('data/test.csv')\n",
        "\n",
        "print(\"Training data shape:\", train_df.shape)\n",
        "print(\"\\nTraining data:\")\n",
        "print(train_df)\n",
        "print(\"\\nTest data shape:\", test_df.shape)\n",
        "print(\"\\nTest data:\")\n",
        "print(test_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label distribution:\n",
            "label\n",
            "ingredient_only        3\n",
            "ingredient_with_qty    3\n",
            "instruction_like       3\n",
            "non_food               3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique labels: ['ingredient_only' 'ingredient_with_qty' 'instruction_like' 'non_food']\n"
          ]
        }
      ],
      "source": [
        "# Check label distribution\n",
        "print(\"Label distribution:\")\n",
        "print(train_df['label'].value_counts())\n",
        "print(\"\\nUnique labels:\", train_df['label'].unique())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "\n",
        "Looking at the patterns:\n",
        "- `ingredient_with_qty`: contains numbers/units (g, ml, kg, etc.)\n",
        "- `instruction_like`: contains action verbs (chop, simmer, stir, etc.)\n",
        "- `non_food`: items like \"plastic wrap\", \"baking paper\"\n",
        "- `ingredient_only`: simple ingredient names\n",
        "\n",
        "Let me try a simple approach with TF-IDF first, but I'll also add some rule-based features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples with quantities:\n",
            "  Butter 50 g\n",
            "  Milk 200 ml\n",
            "\n",
            "Examples that look like instructions:\n",
            "  Chop the onions\n",
            "  Simmer for 10 minutes\n",
            "  Slice the bread\n"
          ]
        }
      ],
      "source": [
        "# Let's look at some patterns manually\n",
        "print(\"Examples with quantities:\")\n",
        "for text in train_df['text']:\n",
        "    if re.search(r'\\d+\\s*(g|ml|kg|l|G|ML|KG|L)', text, re.IGNORECASE):\n",
        "        print(f\"  {text}\")\n",
        "\n",
        "print(\"\\nExamples that look like instructions:\")\n",
        "instruction_keywords = ['chop', 'simmer', 'stir', 'slice', 'warm', 'mix']\n",
        "for text in train_df['text']:\n",
        "    if any(kw in text.lower() for kw in instruction_keywords):\n",
        "        print(f\"  {text}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on 12 examples\n",
            "Predicting on 8 examples\n"
          ]
        }
      ],
      "source": [
        "# Prepare data\n",
        "X_train = train_df['text'].values\n",
        "y_train = train_df['label'].values\n",
        "X_test = test_df['text'].values\n",
        "\n",
        "print(f\"Training on {len(X_train)} examples\")\n",
        "print(f\"Predicting on {len(X_test)} examples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rule-based features shape: (12, 3)\n",
            "Sample features: [[0 0 0]\n",
            " [0 0 0]\n",
            " [1 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# Let me try a different approach - add some simple features manually\n",
        "# Since we have very few examples, rule-based features might help\n",
        "\n",
        "def has_quantity(text):\n",
        "    \"\"\"Check if text has a quantity (number + unit)\"\"\"\n",
        "    return 1 if re.search(r'\\d+\\s*(g|ml|kg|l|gram|grams|liter|liters)', text.lower()) else 0\n",
        "\n",
        "def has_instruction_verb(text):\n",
        "    \"\"\"Check if text has instruction verbs\"\"\"\n",
        "    verbs = ['chop', 'simmer', 'stir', 'slice', 'warm', 'mix', 'cook', 'heat', 'boil', 'fry']\n",
        "    return 1 if any(verb in text.lower() for verb in verbs) else 0\n",
        "\n",
        "def has_non_food_keyword(text):\n",
        "    \"\"\"Check if text has non-food keywords\"\"\"\n",
        "    keywords = ['wrap', 'paper', 'foil', 'towel', 'plastic', 'baking', 'aluminum']\n",
        "    return 1 if any(kw in text.lower() for kw in keywords) else 0\n",
        "\n",
        "# Extract rule-based features for training data\n",
        "X_train_features = []\n",
        "for text in X_train:\n",
        "    feat = [has_quantity(text), has_instruction_verb(text), has_non_food_keyword(text)]\n",
        "    X_train_features.append(feat)\n",
        "\n",
        "X_train_features = np.array(X_train_features)\n",
        "print(\"Rule-based features shape:\", X_train_features.shape)\n",
        "print(\"Sample features:\", X_train_features[:3])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF features shape: (12, 38)\n",
            "Combined features shape: (12, 41)\n",
            "Model trained!\n"
          ]
        }
      ],
      "source": [
        "# Now let's get TF-IDF features\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Get TF-IDF features\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 2), lowercase=True, min_df=1)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "\n",
        "print(\"TF-IDF features shape:\", X_train_tfidf.shape)\n",
        "\n",
        "# Combine rule-based and TF-IDF features\n",
        "X_train_combined = hstack([csr_matrix(X_train_features), X_train_tfidf])\n",
        "print(\"Combined features shape:\", X_train_combined.shape)\n",
        "\n",
        "# Try logistic regression with balanced weights\n",
        "model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
        "model.fit(X_train_combined, y_train)\n",
        "print(\"Model trained!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set performance:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "    ingredient_only       1.00      1.00      1.00         3\n",
            "ingredient_with_qty       1.00      1.00      1.00         3\n",
            "   instruction_like       1.00      1.00      1.00         3\n",
            "           non_food       1.00      1.00      1.00         3\n",
            "\n",
            "           accuracy                           1.00        12\n",
            "          macro avg       1.00      1.00      1.00        12\n",
            "       weighted avg       1.00      1.00      1.00        12\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Check performance on training data\n",
        "y_train_pred = model.predict(X_train_combined)\n",
        "print(\"Training set performance:\")\n",
        "print(classification_report(y_train, y_train_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions:\n",
            "                 text                 pred\n",
            "0              Garlic      ingredient_only\n",
            "1          Sugar 20 g  ingredient_with_qty\n",
            "2       Warm in a pan     instruction_like\n",
            "3       Aluminum foil             non_food\n",
            "4          Rice 150 g  ingredient_with_qty\n",
            "5               Cumin      ingredient_only\n",
            "6  Stir for 2 minutes     instruction_like\n",
            "7                Salt      ingredient_only\n"
          ]
        }
      ],
      "source": [
        "# Extract features for test set\n",
        "X_test_features = []\n",
        "for text in X_test:\n",
        "    feat = [has_quantity(text), has_instruction_verb(text), has_non_food_keyword(text)]\n",
        "    X_test_features.append(feat)\n",
        "\n",
        "X_test_features = np.array(X_test_features)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "X_test_combined = hstack([csr_matrix(X_test_features), X_test_tfidf])\n",
        "\n",
        "# Predict on test set\n",
        "y_test_pred = model.predict(X_test_combined)\n",
        "\n",
        "# Create predictions dataframe\n",
        "predictions_df = pd.DataFrame({\n",
        "    'text': X_test,\n",
        "    'pred': y_test_pred\n",
        "})\n",
        "\n",
        "print(\"Predictions:\")\n",
        "print(predictions_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Checking predictions:\n",
            "1. 'Garlic' -> ingredient_only\n",
            "2. 'Sugar 20 g' -> ingredient_with_qty\n",
            "3. 'Warm in a pan' -> instruction_like\n",
            "4. 'Aluminum foil' -> non_food\n",
            "5. 'Rice 150 g' -> ingredient_with_qty\n",
            "6. 'Cumin' -> ingredient_only\n",
            "7. 'Stir for 2 minutes' -> instruction_like\n",
            "8. 'Salt' -> ingredient_only\n"
          ]
        }
      ],
      "source": [
        "# Let's check if predictions make sense\n",
        "print(\"\\nChecking predictions:\")\n",
        "for i, (text, pred) in enumerate(zip(X_test, y_test_pred)):\n",
        "    print(f\"{i+1}. '{text}' -> {pred}\")\n",
        "    \n",
        "    # Quick validation\n",
        "    if has_quantity(text) and pred != 'ingredient_with_qty':\n",
        "        print(f\"   (has quantity but predicted as {pred})\")\n",
        "    if has_instruction_verb(text) and pred != 'instruction_like':\n",
        "        print(f\"   (has instruction verb but predicted as {pred})\")\n",
        "    if has_non_food_keyword(text) and pred != 'non_food':\n",
        "        print(f\"   (has non-food keyword but predicted as {pred})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save predictions\n",
        "predictions_df.to_csv('predictions.csv', index=False)\n",
        "print(\"Saved predictions to predictions.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
